{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "import ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling dde5aa3fc5ff... 100% ▕████████████████▏ 2.0 GB                         \n",
      "pulling 966de95ca8a6... 100% ▕████████████████▏ 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% ▕████████████████▏ 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% ▕████████████████▏ 6.0 KB                         \n",
      "pulling 56bb8bd477a5... 100% ▕████████████████▏   96 B                         \n",
      "pulling 34bb5ab01051... 100% ▕████████████████▏  561 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "# os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "# Constants\n",
    "\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given URL using the BeautifulSoup library.\n",
    "        Includes error handling for network errors and parsing failures.\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        self.title = \"No title found\"\n",
    "        self.text = \"No content extracted\"\n",
    "\n",
    "        try:\n",
    "            # Send an HTTP GET request to fetch the webpage\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()  # Raises an HTTPError for bad responses (4xx and 5xx)\n",
    "\n",
    "            # Parse the HTML content with BeautifulSoup\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            # Extract the title if available\n",
    "            self.title = soup.title.string if soup.title else \"No title found\"\n",
    "\n",
    "            # Ensure <body> tag exists before processing text\n",
    "            if soup.body:\n",
    "                # Remove unnecessary elements (scripts, styles, images, inputs)\n",
    "                for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                    irrelevant.decompose()\n",
    "\n",
    "                # Extract the cleaned text content\n",
    "                self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "            else:\n",
    "                self.text = \"No body content found\"\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching URL {url}: {e}\")\n",
    "            self.text = f\"Error: Unable to retrieve content from {url}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error while processing {url}: {e}\")\n",
    "            self.text = \"Error: Something went wrong during parsing.\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt\n",
    "\n",
    "\n",
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\"\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]\n",
    "\n",
    "# And now: call the Ollama function instead of OpenAI\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    messages = messages_for(website)\n",
    "    response = ollama.chat(model=MODEL, messages=messages)\n",
    "    return response['message']['content']\n",
    "\n",
    "\n",
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Website Summary\n",
       "\n",
       "#### Overview\n",
       "\n",
       "The website is hosted by Edward Donner, a co-founder and CTO of Nebula.io, an AI startup that applies machine learning to help people discover their potential. The site features various sections, including about the company, its products, and community engagement.\n",
       "\n",
       "#### Recent Announcements\n",
       "\n",
       "* **LLM Workshop - Hands-on with Agents - resources** (January 23, 2025): A workshop providing resources for working with LLMs.\n",
       "* **Welcome, SuperDataScientists!** (November 13, 2024): An announcement welcoming a new group of professionals in the field of machine learning.\n",
       "* **Mastering AI and LLM Engineering - Resources** (October 16, 2024): A set of resources for improving skills in AI and LLM engineering.\n",
       "\n",
       "#### Website Content\n",
       "\n",
       "The website features various links to projects, including:\n",
       "\n",
       "* **Connect Four**: A game that can be played online.\n",
       "* **Outsmart**: An arena where LLMs compete against each other in a battle of diplomacy and deviousness.\n",
       "* **About**: Information about Edward Donner, the company Nebula.io, and its mission.\n",
       "\n",
       "#### Contact Information\n",
       "\n",
       "The website includes contact information for Edward Donner, including an email address and social media links."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The article appears to be a news aggregator from CNN, featuring a wide range of topics and stories from around the world. Here are some of the main headlines and summaries:\n",
       "\n",
       "**World News**\n",
       "\n",
       "* Over 3,000 killed in fighting in Africa's mineral-rich DRC\n",
       "* Georgia slides into authoritarianism, protesters vow to keep fighting Russian pivot\n",
       "* Suspect in Brazil Christmas cake poisonings found dead in prison cell\n",
       "\n",
       "**Business and Technology**\n",
       "\n",
       "* Apple picks Alibaba to launch AI features in China\n",
       "* Elon Musk will withdraw his nearly $100 billion bid for OpenAI if it remains a nonprofit\n",
       "* Duolingo's cute owl mascot is dead. It is an ex-owl\n",
       "\n",
       "**Health and Wellness**\n",
       "\n",
       "* Anxiety can be debilitating. Controlling it starts with this simple step, Martha Beck says\n",
       "* The secret to great sex isn’t really a secret. It’s asking the right question, 81-year-old sex professor says\n",
       "* Netflix’s ‘Apple Cider Vinegar’ takes aim at wellness influencers, but there’s another problem\n",
       "\n",
       "**Entertainment**\n",
       "\n",
       "* David J. Phillip/AP: Photos of celebrities and events from around the world\n",
       "* The week in 32 photos\n",
       "\n",
       "**Sports**\n",
       "\n",
       "* Football: NFL players protest police brutality on field\n",
       "* Tennis: Naomi Osaka wins Australian Open final\n",
       "\n",
       "**Politics**\n",
       "\n",
       "* Vance turns on European allies in blistering speech that downplayed threats from Russia and China\n",
       "* Friedrich Merz, Merkel’s rival and German election frontrunner\n",
       "\n",
       "**Science and Space**\n",
       "\n",
       "* Stunning photographs capture starling migrations\n",
       "* Climate: Solutions to address climate change\n",
       "\n",
       "**Other Topics**\n",
       "\n",
       "* Fighting in Africa's mineral-rich DRC killed over 3,000 in less than 2 weeks. Here’s how your phone plays a part\n",
       "* No doctors for sick children. This is the reality of Trump’s aid freeze in remote northern Thailand"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching URL https://cripsa.com: HTTPSConnectionPool(host='cripsa.com', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x1097f5220>, 'Connection to cripsa.com timed out. (connect timeout=10)'))\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Website Summary\n",
       "\n",
       "Unfortunately, the requested website `https://cripsa.com` could not be retrieved, likely due to an error in the provided URL.\n",
       "\n",
       "However, I can provide a general summary of what it would look like if this website had a content section:\n",
       "\n",
       "#### Featured Content\n",
       "\n",
       "*   This section could include any high-profile features or announcements made on the website.\n",
       "*   It might feature links to blog posts, news articles, or press releases that summarize key events or updates.\n",
       "\n",
       "#### About Us/Our Mission\n",
       "\n",
       "*   This section would typically provide an overview of the organization's purpose, values, and goals.\n",
       "*   It could also include a brief history of the company or its founders.\n",
       "\n",
       "### Note\n",
       "The lack of content on this website makes it difficult to provide a detailed summary."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://cripsa.com\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
